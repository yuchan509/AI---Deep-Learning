{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Embedding\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 문장을 잘라줌.\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평점</th>\n",
       "      <th>평가글</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>B급 이하전편보다 퇴보된 CG, 중구난방식 연출, 러닝타임 늘리기 위한 쓸모없는 컷...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>이딴 영화가 평점 8점 후반대라는 게 믿기지 않는다. 역시 네이버 평점은 믿고 걸러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>역시 원더우먼 영화는 주연배우 갤가돗과 크리스파인이 다 살리네.. 감독은 확실히 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>히어로물의 액션을 기대했음. 그러나 졸렬한 액션과 이상한 전개로 마지막 영화관을 나...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    평점                                                평가글\n",
       "0  1.0  B급 이하전편보다 퇴보된 CG, 중구난방식 연출, 러닝타임 늘리기 위한 쓸모없는 컷...\n",
       "1  3.0  이딴 영화가 평점 8점 후반대라는 게 믿기지 않는다. 역시 네이버 평점은 믿고 걸러...\n",
       "2  6.0  역시 원더우먼 영화는 주연배우 갤가돗과 크리스파인이 다 살리네.. 감독은 확실히 영...\n",
       "3  2.0          진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ\n",
       "4  1.0  히어로물의 액션을 기대했음. 그러나 졸렬한 액션과 이상한 전개로 마지막 영화관을 나..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링을 통한 네이버 영화 평점 및 평가글 등 데이터를 가져옴.\n",
    "df = pd.read_csv('data/naver_star_data.csv')\n",
    "df.head()\n",
    "\n",
    "# 평점 및 평가글만 가져옴.\n",
    "# 253691개의 데이터.\n",
    "df2 = df[['평점', '평가글']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253691"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거.\n",
    "df2.isna().sum()\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "# 평점이 5점 이하는 0으로 변환.\n",
    "a1 = df2.query('평점<=5').index\n",
    "df2.loc[a1, '평점'] = 0\n",
    "\n",
    "# 평점이 5점 이상은 1로 변환.\n",
    "a1 = df2.query('평점>=5').index\n",
    "df2.loc[a1, '평점'] = 1\n",
    "\n",
    "# 평가글 추출.\n",
    "docs = df2['평가글'].values\n",
    "docs\n",
    "\n",
    "# 결과 추출,\n",
    "classes = df2['평점'].values\n",
    "classes \n",
    "\n",
    "# 토큰화.\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "\n",
    "# 단어 사전을 통해 문장의 각 단어를 숫자로 변환.\n",
    "x = token.texts_to_sequences(docs)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 단어의 개수 :  48\n"
     ]
    }
   ],
   "source": [
    "# 한 문장의 최대 단어 수를 가져옴.\n",
    "max_cnt = 0\n",
    "for c in x :\n",
    "    # 현재 문장의 글자수.\n",
    "    cnt = len(c)\n",
    "    # 현재 문장의 글자수가 이전 최대 수치보다 많으면 덮어씌움.\n",
    "    if max_cnt < cnt :\n",
    "        max_cnt = cnt\n",
    "print('최대 단어의 개수 : ', max_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0, ...,     56,   9293,  17911],\n",
       "       [     0,      0,      0, ...,  63776,    231, 101809],\n",
       "       [     0,      0,      0, ...,  25328,     90,    422],\n",
       "       ...,\n",
       "       [     0,      0,      0, ..., 383505, 383506,  27644],\n",
       "       [     0,      0,      0, ...,   1432,     37,    239],\n",
       "       [     0,      0,      0, ...,  12420, 383512,   7694]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding => 서로 길이가 다른 리스트의 개수를 max_cnt로 맞춰줌.\n",
    "padded_x = pad_sequences(x, max_cnt)\n",
    "padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7928/7928 [==============================] - 145s 18ms/step - loss: 0.3074 - accuracy: 0.8806\n",
      "Epoch 2/20\n",
      "7928/7928 [==============================] - 152s 19ms/step - loss: 0.1567 - accuracy: 0.9397\n",
      "Epoch 3/20\n",
      "7928/7928 [==============================] - 159s 20ms/step - loss: 0.1039 - accuracy: 0.9627\n",
      "Epoch 4/20\n",
      "7928/7928 [==============================] - 162s 20ms/step - loss: 0.0700 - accuracy: 0.9766\n",
      "Epoch 5/20\n",
      "7928/7928 [==============================] - 150s 19ms/step - loss: 0.0490 - accuracy: 0.9844\n",
      "Epoch 6/20\n",
      "7928/7928 [==============================] - 151s 19ms/step - loss: 0.0352 - accuracy: 0.9887\n",
      "Epoch 7/20\n",
      "7928/7928 [==============================] - 139s 17ms/step - loss: 0.0252 - accuracy: 0.9919\n",
      "Epoch 8/20\n",
      "7928/7928 [==============================] - 138s 17ms/step - loss: 0.0187 - accuracy: 0.9940\n",
      "Epoch 9/20\n",
      "7928/7928 [==============================] - 138s 17ms/step - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 10/20\n",
      "7928/7928 [==============================] - 140s 18ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 11/20\n",
      "7928/7928 [==============================] - 143s 18ms/step - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 12/20\n",
      "7928/7928 [==============================] - 144s 18ms/step - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 13/20\n",
      "7928/7928 [==============================] - 144s 18ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 14/20\n",
      "7928/7928 [==============================] - 169s 21ms/step - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 15/20\n",
      "7928/7928 [==============================] - 169s 21ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 16/20\n",
      "7928/7928 [==============================] - 169s 21ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 17/20\n",
      "7928/7928 [==============================] - 169s 21ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 18/20\n",
      "7928/7928 [==============================] - 170s 21ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 19/20\n",
      "7928/7928 [==============================] - 168s 21ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 20/20\n",
      "7928/7928 [==============================] - 166s 21ms/step - loss: 0.0042 - accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x297e8ea6c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어의 수를 파악.\n",
    "word_size = len(token.word_index) + 1\n",
    "\n",
    "# 학습 모델을 구성.\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size, 8, input_length=max_cnt))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 컴파일.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 학습.\n",
    "model.fit(padded_x, classes, epochs=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7928/7928 [==============================] - 11s 1ms/step - loss: 0.0037 - accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9987662434577942"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도.\n",
    "model.evaluate(padded_x, classes)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 문장 생성.\n",
    "docs = [\n",
    "    '이 영화 재미있어요',\n",
    "    '이 영화 재미 없어요',\n",
    "    '추천 드립니다',\n",
    "    '추천 드리지 않습니다'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측.\n",
    "# 1 : 긍정, 0 : 부정\n",
    "x = token.texts_to_sequences(docs)\n",
    "padded_x = pad_sequences(x, max_cnt)\n",
    "pred = (model.predict(padded_x) > 0.5).astype('int32')\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
