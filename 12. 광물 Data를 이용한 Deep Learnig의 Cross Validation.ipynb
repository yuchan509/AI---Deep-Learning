{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "# 그래프 설정.\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# String Encoding.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "# 다중분류를 위한 핫-윈 인코더.\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 평가.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sed 설정.\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "5  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "6  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "7  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
       "8  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "9  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "5  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "6  0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
       "7  0.2838  ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
       "8  0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
       "9  0.0251  ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "5  0.0051  0.0062   R  \n",
       "6  0.0036  0.0103   R  \n",
       "7  0.0048  0.0053   R  \n",
       "8  0.0059  0.0022   R  \n",
       "9  0.0056  0.0040   R  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 읽기.\n",
    "df = pd.read_csv('data/sonar.csv', header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정보 확인.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 데이터와 타겟 데이터 분할.\n",
    "x = df.drop(60, axis=1)\n",
    "y = df[60]\n",
    "\n",
    "# 문자열 데이터 y를 숫자로 변환.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold를 이용한 교차 검증(Cross Validation)\n",
    "# 시행 목적 : 과소 과대 적합문제를 방지.\n",
    "# k-fold 생성.\n",
    "# 10개의 dataset으로 분할.\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5459 - accuracy: 0.9048\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3591 - accuracy: 0.9048\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6598 - accuracy: 0.8571\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2836 - accuracy: 0.8095\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3509 - accuracy: 0.9524\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9037 - accuracy: 0.7619\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.6433e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4732 - accuracy: 0.8095\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7122 - accuracy: 0.8095\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9947\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2501 - accuracy: 0.9000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1959 - accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# 예측 정확도를 담을 리스트.\n",
    "Train_result_List = []\n",
    "Test_result_List  = []\n",
    "\n",
    "# < 모델의 설정, 컴파일, 실행 >\n",
    "for train_idx, test_idx in skf.split(x, y) :\n",
    "    # print(x.loc[train_idx])\n",
    "    # 모델 설정.\n",
    "    model = Sequential()\n",
    "\n",
    "    # 60개의 노드로 이루어진 1개의 입력층과 2개의 은닉층 설정.\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "\n",
    "    # 출력층. 이진 분류이므로 sigmoid 통과.\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # 모델 컴파일.\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # 모델 실행.\n",
    "    model.fit(x.loc[train_idx], y[train_idx], epochs=100, batch_size=5, verbose=1)\n",
    "    \n",
    "    # 검증.\n",
    "    # 학습 데이터에 대한 성능을 평가.\n",
    "    # 당연히 잘 나와야함.\n",
    "    score1 = model.evaluate(x.loc[train_idx], y[train_idx])[1]\n",
    "    \n",
    "    # 학습하지 않은 데이터를 통한 평가.\n",
    "    score2 = model.evaluate(x.loc[test_idx], y[test_idx])[1]\n",
    "    \n",
    "    # 각 Score 값 각 리스트에 담기.\n",
    "    Train_result_List.append(score1)\n",
    "    Test_result_List.append(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9946808218955994, 1.0]\n",
      "[0.9047619104385376, 0.9047619104385376, 0.8571428656578064, 0.8095238208770752, 0.9523809552192688, 0.761904776096344, 0.8095238208770752, 0.8095238208770752, 0.8999999761581421, 0.8500000238418579]\n"
     ]
    }
   ],
   "source": [
    "# 비교.\n",
    "# Train dataset을 통한 평가는 당연히 Train data를 이용하여 학습된 모델이므로 좋은 성능을 보이는 것이 당연하며 100% 정확도를 보임.\n",
    "# 반면 Test dataset을 통한 정확도는 들쑥 날쑥한 양상을 보이며, 성능 역시 안 좋은 경우가 과반수임.\n",
    "# 즉 차이가 두드러지게 나타나고 있음.\n",
    "# 과소적합 문제가 발생하고 있다고 판단이 가능.\n",
    "print(Train_result_List)\n",
    "print(Test_result_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화.\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Train_result_List, color='tomato', alpha=.5)\n",
    "plt.plot(Test_result_List, color='m', alpha=.5)\n",
    "plt.legend(['Train',' Test'])\n",
    "plt.xlabel('K-fold : 10')\n",
    "plt.ylabel('Accuravy')\n",
    "plt.ylim(0, 1.2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
